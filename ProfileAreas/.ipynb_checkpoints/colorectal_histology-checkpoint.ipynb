{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1701096641977,
     "user": {
      "displayName": "Sh Akh",
      "userId": "05053716267767509812"
     },
     "user_tz": -60
    },
    "id": "A-OshF9FPP9s"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import tensorflow_datasets as tfds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1701097420933,
     "user": {
      "displayName": "Sh Akh",
      "userId": "05053716267767509812"
     },
     "user_tz": -60
    },
    "id": "ra37QoCEPfLb"
   },
   "outputs": [],
   "source": [
    "def load_img_data_colorectal_histology(img_size):\n",
    "    dataset = tfds.load('colorectal_histology', split=['train'], as_supervised=True)\n",
    "    array = np.vstack(tfds.as_numpy(dataset[0]))\n",
    "    x_data = np.array(list(map(lambda x: x[0], array)))\n",
    "    y_data = np.array(list(map(lambda x: x[1], array)))\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.3, stratify=y_data)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.25, stratify=y_val)\n",
    "\n",
    "    print('Number of training images: %i' %X_train.shape[0])\n",
    "    print('Number of validation images: %i' %X_val.shape[0])\n",
    "    print('Number of test images: %i' %X_test.shape[0])\n",
    "    print('Image Size: ', X_train[0].shape)\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "\n",
    "def preprocessed_dataset(n_classes, img_size):\n",
    "    (x_train, y_train), (x_val, y_val), (x_test, y_test) = load_img_data_colorectal_histology(img_size)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_val = x_val.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=n_classes)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=n_classes)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes=n_classes)\n",
    "\n",
    "    print('x_train: ', x_train.shape)\n",
    "    print('y_train: ', y_train.shape)\n",
    "\n",
    "    train_DataGen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                                              zoom_range=0.2,\n",
    "                                                              width_shift_range=0.1,\n",
    "                                                              height_shift_range = 0.1,\n",
    "                                                              horizontal_flip=True\n",
    "                                                              )\n",
    "\n",
    "    valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "    train_set = train_DataGen.flow(x_train, y_train, batch_size=32)\n",
    "    valid_set = valid_datagen.flow(x_val, y_val, batch_size=32)\n",
    "    test_set = test_datagen.flow(x_test, y_test, batch_size=1)\n",
    "\n",
    "    return train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTObVQTDTUL7",
    "outputId": "c120e0ce-08cb-4c34-c109-76085a13e92f"
   },
   "outputs": [],
   "source": [
    "img_size = 150\n",
    "n_classes = 8\n",
    "\n",
    "train_set, valid_set, test_set = preprocessed_dataset(n_classes, img_size)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = None\n",
    "\n",
    "#########################################\n",
    "#########################################\n",
    "#Add Model definition here!\n",
    "#########################################\n",
    "#########################################\n",
    "    \n",
    "    \n",
    "sgd = SGD(learning_rate = 0.01, momentum = 0.9, nesterov = True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape = (None, img_size, img_size, 3))\n",
    "model.summary()\n",
    "\n",
    "fit_history = model.fit(train_set,\n",
    "              validation_data = valid_set,\n",
    "              epochs = 200,\n",
    "              verbose = 1)\n",
    "\n",
    "loss_val = fit_history.history['loss']\n",
    "loss, acc = model.evaluate(test_set, verbose=0)\n",
    "\n",
    "test_accuracy = 'Test set accuracy is: %f' %acc\n",
    "print(test_accuracy)\n",
    "\n",
    "\n",
    "now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "hist = pd.DataFrame(fit_history.history) \n",
    "csv_file = now + '_training_curve.csv'\n",
    "with open(csv_file, mode='w') as f:\n",
    "    hist.to_csv(f)\n",
    "    f.write(test_accuracy)\n",
    "\n",
    "pyplot.figure(1, figsize = (15,8))\n",
    "\n",
    "pyplot.subplot(221)\n",
    "pyplot.plot(fit_history.history['accuracy'])\n",
    "pyplot.plot(fit_history.history['val_accuracy'])\n",
    "pyplot.title('model accuracy')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'valid'])\n",
    "\n",
    "pyplot.subplot(222)\n",
    "pyplot.plot(fit_history.history['loss'])\n",
    "pyplot.plot(fit_history.history['val_loss'])\n",
    "pyplot.title('model loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'valid'])\n",
    "\n",
    "filename = now + '_loss_curve' + '.tif'\n",
    "pyplot.savefig(filename)\n",
    "pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LI8KF-QAToVK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOOllDZi9LwUIrpLjWoS/IA",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
